\chapter{Generative Adversarial Networks}\label{chap:Arch2}

A \acf{GAN} is a pair of competing networks; a generator and a discriminator contest each other in a zero-sum game. The goal of the generator is to fool the discriminator by generating content which cannot reliably be differentiated from real ground-truth content. The discriminator attempts to tell generated content apart from real data. Each network is trained as the other's loss function (or one thereof).

The main advantage of a \ac{GAN} is that the loss function of the generator is learned; it does not need to be defined so the trained generator can reach performance exceeding that of a generator trained with a conventional loss. The conventional loss function is a limiting factor because it cannot quantify realism, especially in the case of a one-to-many mapping between a noisy image and the acceptable generated counterparts. The generator can learn to restore high-frequency details which cannot be determined from the noisy observation alone whereas the best score it can obtain with a conventional loss function is by averaging the many possible solutions or overfitting the training data.

Moreover, data may sometimes be used for training without a matching pair of ground-truth - corrupted representations. This can be very useful when paired data is not available, or to further train a network in order to learn specific tasks. It is not always possible to train a \ac{GAN} without paired data. This is the case with \acsp{cGAN} which always take the noisy observation as the conditional input in addition to either the generated or ground-truth data, although a \ac{cGAN} may be trained with the noisy portion of the data, or with an adapted training protocol (such as blurring the noisy representation or using a label instead of an image). Regardless, the generator can be trained with a pre-trained discriminator.

The discriminating network differs from the generative networks presented in chapter \ref{chap:Arch1} in that they classify the output image by outputting a single $1\times 1 \times 1$ probability. A \ac{GAN} is a system that comprises both a discriminative and a generative network.

\section{Types of GANs}

\begin{itemize}
  \item The \acs{GAN} is the simplest and initial approach introduced by Goodfellow et al. \cite{gan}. A generator is given a noisy input, then the discriminator trains on a mini-batch made of the generated data and another mini-batch containing ground-truth data.

A \ac{GAN} does not necessarily need clean-noisy pairs of images because it only receives one image at a time. However, this feature may lead the generator to learn a mapping which has the realistic features required to trick the discriminator but does not resemble the original image. For this reason we often combine the discriminator loss with a conventional loss function such as SSIM or L1 (and these losses do require a pair of clean-noisy images). \acp{GAN} could still be used for semi-supervised learning by training with conventional losses and a paired dataset until satisfying performance is met, then training further with a non-paired dataset using the GAN only. This could be beneficial for specialized images which would be tricky to include in a paired dataset, such as those depicting moving subjects and living faces.

While it may seem counter-intuitive to train the discriminator with mini-batches of only one label at a time, this practice may be justified with the use of \acl{BN}. This strategy keeps running statistics and normalizes the activations on the given batch, enabling the \ac{GAN} to potentially perform better given low-variance input data. \cite{gantechniques} % TODO Our data is fed as a mix of different ISO values and could explain why the generator does not perform as well with BN
  \item Conditional generative adversarial networks are \acsp{GAN} which take two inputs: the generated data and typically a label that describes it \cite{cgan}. An approach often used in image generation is to concatenate the corrupted image with the generated input and feed these image pairs as the input data rather than using a label \cite{pix2pix}\cite{cyclegan}\cite{pix2pixhd}. The benefit of potentially semi-supervised learning is no longer present but the discriminator is built-in with a correlative loss and the network is less likely to require a conventional loss function. While the conditional discriminator needs paired data to learn, a generator can still learn from unmatched data with a pretrained conditional discriminator.
\end{itemize}
CycleGAN \cite{cyclegan} is a popular approach which enforces cyclic consistency, that is, the network must be able to regenerate the corrupted observation back from the generated one. We believe this approach would not function well for the problem of image denoising because of the random nature of noise, whereas CycleGAN applications tend to have simple outlines as the corrupted observation.

The original \ac{GAN} and the commonly used \ac{DCGAN} use the \ac{BCE} loss which is defined as $\text{BCE}(\text{prediction}, \text{target})=-(\text{prediction}\cdot{\log{\text{target}}}+(1-\text{prediction})\cdot \log{(1-\text{target})})$. \ac{BCE} assumes a sigmoid final output activation and a target probability between 0 and 1. It is used in recent image-to-image translation methods such as pix2pix \cite{pix2pix} and CycleGAN \cite{cyclegan}.

The \ac{GAN}'s log-based \ac{BCE} loss suffers from the vanishing gradient problem, where the discriminator's gradient reaches zero, thus the generator no longer receives any information to learn. The \acf{LSGAN} mitigates this issue using the \acl{MSE} loss function which penalizes samples based on their distance from the decision boundary (e.g. a 0.5 uncertainty gives out a loss of $0.5^2=0.25$ while a mistaken 0.9 probability has a loss of $0.9^2=0.81$) and provides more stable training.

\section{Chosen GAN}\label{HulDisc}

Our generator architectures are the U-Net \cite{unet} and Hulbnet mentioned in chapter \ref{chap:Arch1}. For the discriminator classifier we have experienced with PatchGAN \cite{pix2pix} as well as our HulDisc architectures.

PatchGAN is a convolutional classifier intended to capture high-frequency details on small patches and leave the low-frequencies up to the $\ell 1$ loss. The network architecture is made up of five convolutions with $4 \times 4$ kernels and 1 to 2 stride. The last layer returns one feature per patch instead of a single feature for the whole image. The overlapping patches have a $70 \times 70$ pixel receptive field and it is up to the chosen \ac{MSE} loss function to reconcile these losses into a single value.

The HulDisc discriminator uses an architecture similar to the HulbNet generator, but the network is cut in half such that it ends with a single feature instead of upsampling back to the original image size with transposed convolutions. Another difference is the use of \acl{BN}. Our main discriminator focuses on $112\times 112$ pixel crops, this allows for an 8-pixels border not to be discriminated against. The network is fully convolutional and encodes the whole image down to a single pixel/feature, with stride convolutions (stride = 3) downscaling the crops from 102 to 34 and from 18 to 6 pixels, the rest being dense combinations of standard $3\times 3$ convolutions and dilated convolutions (dilation=2) followed by \ac{PReLU} and \acl{BN}. This architecture was developed through experimentation with different combinations, namely the use of batch normalization, different (or no) activation functions, the use of a final pooling layer in place of a stride convolution, the effect of mixed losses, the use of a bottleneck $1\times 1$ convolution layer, and different numbers of filters.

\section{Training methods}

Our (c)GAN training procedures went through multiple experimental iterations.

Our initial method is summarized in section \ref{sec:Initial training method}. Our final method, which appears to provide more stable training requiring fewer parameters, is described in section \ref{sec:Adopted training method}.

%TODO mix of L1 and SSIM: cite https://pdfs.semanticscholar.org/0434/70c64627c074e1a7634a2508ee7e4ec98cd7.pdf
\subsection{Initial training method}\label{sec:Initial training method}
Our initial (c)GAN training method is similar to that of Isola et al. \cite{pix2pix} but with an unequal learning ratio for the discriminator and generator, typically 1:3, because the generator does not learn well when the discriminator is too strong. The method consists of training the discriminator with both a real and a generated minibatch of images, then training the generator using a loss function made of the updated discriminator for high-frequencies and the $\ell 1$ loss for smooth textures. We enhanced the network further by adding the \ac{SSIM} loss.

We found that a generative network trained with the discriminator from the start would never learn to perform well, but a pre-trained generative network could often perform better over time (although a balance must be reached because the discriminator cannot catch up to a too well-trained generator). We added a minimum SSIM score over a specified number of consecutive iterations before adding the discriminator as part of the generator's loss. Although the discriminator is being trained all along, the generator does not receive its feedback until the set threshold is met. From this point, the loss function is a weighted combination of the discriminator's \ac{MSE} loss (typically 0.75); the \ac{SSIM} index (0.20) which ensures stability and image quality; and the $\ell 1$ loss (0.05) which provides some smoothness to prevent excessive high-frequency details caused by the discriminator. Switching loss functions multiple times throughout training did not seem to yield viable results.

Balanced initialization is crucial as our experimental work has shown that using the discriminator too soon results in a generator whose only focus is to trick the discriminator, and the image quality suffers to the point where the generator loses and its gradient vanishes (the resulting generated images are uniform). However, starting off with a well-trained generator usually results in a discriminator that never learns to discriminate and remains forever indecisive.

The network is still highly susceptible to failure after initialization. Common issues are overconfidence (with eventual mode collapse where the network outputs the same result), vanishing gradients, and indecision, therefore a good balance must be maintained all along the training process. We provide the discriminator's \ac{MSE} loss with noisy labels as recommended by Salimans et al. \cite{gantechniques}\cite{gantutorial} by substracting 0 to 0.05 from the real images' target probabilities to prevent overconfidence. There is typically a 0.33 to 0.5 training ratio between the discriminator and the generator; the imbalance ensures that the two networks are not constantly trying to overcome each other's latest update. This ratio is lowered to 0.1 when the discriminator gets too accurate (95 \%) and it is increased to 0.9 when the discriminator has close to 50 \% (or below) accuracy. 50 \% is the ideal target but it often indicates an indecisive discriminator.

\subsection{Adopted (c)GAN training method}\label{sec:Adopted training method}

We needed a more robust method that can handle varying strength between the discriminator and the generator; that is, the generator must not always learn when the discriminator has to catch up; a constant ratio may end up promoting imbalance; and it may be beneficial for the two networks to learn on different batches of data rather than immediately adjusting for the adversary's most recent update.

Our current method uses the discriminator's normalized loss to determine whether the discriminator and the generator get to learn. A denoised batch is generated then the discriminator learns if its previous normalized loss is smaller than a uniformly distributed random number between 0 and 1. The generator then learns if the discriminator did not learn or if the discriminator's previous performance is greater than another uniformly distributed random number.

The discriminator's normalized loss is between 0 and 1 where 0.5 represents indecision or being right half of the time. For this we simply invert the \ac{MSE} by taking its square root for each set of labels, and we take the average of the two. The generator learns from the discriminator's current (updated) state rather than its previous state (as in the previous method), because this saves significant memory and complexity. All thresholding parameters were removed but we introduced a variable that can be used to give the discriminator an (dis)advantage; that is, whether a network learns is determined by the discriminator's previous loss plus that parameter. For example the intended use of the discriminator advantage variable would be that if it is set to 0.1 and the discriminator has a loss of 0.5, then the discriminator will have a $0.5+0.1=0.6$ probability of learning instead of 0.5 and the generator will learn with a probability of $0.5-0.1=0.4$

% should investigate: https://arxiv.org/abs/1803.07422 (Patch-Based Image Inpainting with Generative Adversarial Networks)
The (c)GAN training procedure is summarized as algorithm \ref{alg:gantrain}. The variables (losses and predictions) are tensors which may contain any number of scalars as well as the whole computation graph (history) and gradients needed to perform the backpropagation.


\begin{algorithm}
\caption{(c)GAN training procedure}\label{alg:gantrain}
\begin{algorithmic}[1]
\FORALL{clean\_batch, noisy\_batch $\in$ Dataset}
\STATE generated\_batch $\leftarrow$ generator(noisy\_batch) \COMMENT{Denoised}
\STATE \COMMENT{Train the discriminator}
\IF{discriminator learns}
\STATE \COMMENT{discriminator learns = discriminator's previous normalized loss > random[0,1]}
\STATE ADAM\_optimizer\_D.clear\_gradient()
\IF{discriminator.is\_conditional}
\STATE fake\_minibatch $\leftarrow$ concatenate(
\STATE \quad remove\_borders(noisy\_batch),
\STATE \quad remove\_borders(generated\_batch))
\STATE real\_minibatch $\leftarrow$ concatenate(
\STATE \quad remove\_borders(noisy\_batch),
\STATE \quad remove\_borders(clean\_batch))
\ELSE
\STATE fake\_minibatch $\leftarrow$ remove\_borders(generated\_batch)
\STATE real\_minibatch $\leftarrow$ remove\_borders(clean\_batch)
\ENDIF
\STATE predictions\_on\_real\_data $\leftarrow$ discriminator(real\_minibatch)
\STATE loss\_real\_D $\leftarrow$ \ac{MSE}(
\STATE \quad predictions\_on\_real\_data,
\STATE \quad generate\_noisy\_probabilities(\TRUE))
\STATE loss\_real\_D.backpropagate()
\STATE predictions\_on\_fake\_data $\leftarrow$
\STATE \quad discriminator(fake\_minibatch.detach\_from\_graph())
\STATE loss\_fake\_D $\leftarrow$ \ac{MSE}(predictions\_on\_fake\_data, \FALSE)
\STATE loss\_fake\_D.backpropagate()
\STATE ADAM\_optimizer\_D.update\_weights()
\ENDIF
\STATE \COMMENT{Train the generator}
\IF{generator learns}
\STATE \COMMENT{generator learns = discriminator didn't learn or discriminator's last normalized loss < random[0,1]}
\STATE predictions\_on\_fake\_data $\leftarrow$ discriminator(fake\_minibatch)
\STATE loss\_G\_GAN $\leftarrow$ \ac{MSE}(predictions\_on\_fake\_data, \TRUE)
\STATE loss\_G\_SSIM $\leftarrow$ \ac{SSIM}(
\STATE \quad remove\_borders(generated\_batch),
\STATE \quad remove\_borders(clean\_batch))
\STATE loss\_G\_$\ell 1\leftarrow \ell 1$(
\STATE \quad remove\_borders(generated\_batch),
\STATE \quad remove\_borders(clean\_batch))
\STATE loss\_G\_weighted $\leftarrow$ 
\STATE \quad loss\_G\_GAN $\times (1- $ weight\_loss\_SSIM $-$ weight\_loss\_$\ell 1)$
\STATE \quad $+$ loss\_G\_SSIM $\times$ weight\_loss\_SSIM
\STATE \quad $+$ loss\_G\_$\ell 1 \times$ weight\_loss\_$\ell 1$
\STATE loss\_G\_weighted.backpropagate()
\STATE ADAM\_optimizer\_G.update\_weights()
\STATE ADAM\_optimizer\_G.clear\_gradient()
\ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}
