\chapter{Generative Adversarial Networks}\label{chap:Arch2}

Generative Adversarial Networks are pairs of competing networks; a generator and a discriminator contest each other in a zero-sum game. The goal of the generator is to fool the discriminator by generating content which cannot reliably be differentiated from real ground-truth content. The discriminator attempts to tell generated content apart from real data. Each network is trained as the other's loss function (or one thereof).

The main advantage of a \acl{GAN} is that the loss function is learned; it does not need to be defined and it can exceed the performance obtained with a conventional loss that is a limiting factor. The generator can learn to restore high-frequency details which cannot be determined from the noisy observation alone (and that are not necessarily visible in the ground-truth) instead of averaging the many possible solutions.

Moreover, data may be added without a matching pair in some scenarios. This does not work with \acl{cGAN} nor can it be combined with other loss functions (combining losses is often necessary to ensure that the result matches and that the details are not overdone), but it can be of great usefulness to further train an existing network to perform better on specialized tasks.

The discriminating network differs from the generative networks presented in chapter \ref{chap:Arch1} in that they classify the output image by outputting a single $1\times 1 \times 1$ probability.

\section{Types of GANs}

\begin{itemize}
  \item A \ac{GAN} is the simplest approach introduced in \cite{gan}. A generator is called with a given input, then the discriminator trains on a mini-batch made of the generated data and another mini-batch containing ground-truth data.

A \ac{GAN} does not necessarily need clean-noisy pairs of images because it only receives one image at a time. However, this feature may lead the generator to learn a mapping which has the features required to trick the discriminator without being related to the input image. For this reason we often combine the discriminator loss with a conventional loss function such as SSIM or L1 (and these losses do require a pair of clean-noisy images). The GAN could still be used for semi-supervised learning by training with conventional losses and a paired dataset until satisfying performance is met, then training further with a non-paired dataset using the GAN only. This could be beneficial for specialized images which would be tricky to include in a paired dataset, such as those depicting moving subjects and living faces.

While it may seem counter-intuitive to train the discriminator with mini-batches of only one label at a time, this practice may be justified with the use of Batch Normalization which keeps running statistics and normalizes the activations on the given batch, it could therefore perform better given low-variance input data. \cite{gantechniques}\cite{bn} % TODO Our data is fed as a mix of different ISO values and could explain why the generator does not perform as well with BN
  \item \ac{cGAN} are \acsp{GAN} which take two inputs, the generated data and typically a label that describes it. An approach often used in image generation is to concatenate the corrupted image with the generated input and feed these image pairs as the input data rather than using a label. \cite{pix2pix}\cite{cyclegan}\cite{pix2pixhd}. The benefit of potentially semi-supervised learning is no longer present but the discriminator is built-in with a correlative loss and the network is less likely to require a conventional loss function. While the conditional discriminator needs paired data to learn, a generator can still learn from unmatched data with a pretrained conditional discriminator.
\end{itemize}
CycleGAN\cite{cyclegan} is a popular approach which enforces cyclic consistency, that is, the network must be able to regenerate the corrupted observation back from the generated one. We believe this approach would not function well for the problem of image denoising because of the random nature of noise, whereas CycleGAN applications tend to have simple outlines as the corrupted observation.

The original \ac{GAN} and commonly used \ac{DCGAN} use the \ac{BCE} loss which is defined as $\text{BCE}(\text{prediction}, \text{target})=-(\text{prediction}\cdot{\log{\text{target}}}+(1-\text{prediction})\cdot \log{(1-\text{target})})$. \ac{BCE} assumes a Sigmoid final output activation and a target probability between 0 and 1, it is used in current image-to-image translation tasks such as \cite{pix2pix}\cite{cyclegan}.

The \ac{GAN}'s log-based \ac{BCE} loss suffers from vanishing gradient where the discriminator's gradient reaches zero thus the generator no longer receives any information to learn. \ac{LSGAN} mitigates this issue using the \acl{MSE} loss function which penalizes samples based on their distance from the decision boundary (ie a 0.5 uncertainty gives out a loss of $0.5^2=0.25$ while a wrong 0.9 probability has a loss of $0.9^2=0.81$) and provides more stable training. \cite{lsgan}

\section{Chosen GAN}

We explored the aforementioned methods, namely \ac{cGAN} and \ac{GAN}, \ac{DCGAN}, and \ac{LSGAN}. Our generator architectures are the U-Net \cite{unet} and Hulbnet mentioned in chapter \ref{chap:Arch1}. For the discriminator classifier we have experienced with PatchGAN \cite{pix2pix} as well as our HulDisc architectures.


PatchGAN is a convolutional classifier intended to capture high-frequency details on small patches and leave the low-frequencies up to the $\ell 1$ loss. The network architecture is made up of five convolutions with $4 \times 4$ kernel and 1 to 2 stride. The last layer returns one feature per patch instead of a single feature for the whole image. The overlapping patches have a $70 \times 70$ pixels receptive field, and it is up to the chosen loss \ac{MSE} function to reconciliate these losses into a single value.

HulDisc uses much the same architecture as the HulbNet generator but without the expanding half and with the addition of Batch Normalization. Our main discriminator focuses on a $112\times 112$ crops, which allows for an undiscriminated-against 8-pixels per side border off the $128^2$-pixels generated images. The network is fully convolutional and encodes the whole image down to a single pixel/feature, with stride convolutions (stride=3) downscaling the crops from 102 to 34 and from 18 to 6 pixels, the rest being dense combinations of standard 3x3 convolutions and dilated convolutions (dilation=2) followed with \ac{PReLU} and \acl{BN}. We experimented with different combinations before getting to this configuration, namely the use of batch normalization, different (or no) activation functions, the use of a final pooling layer, the effect of mixed losses, the use of a bottleneck 1x1 convolution layer, and different numbers of filters.

\section{Training methods}

Our (c)GAN training procedures went through multiple experimental iterations. We first summarize the initial method in section \ref{sec:Initial training method} because is used in some of the experimental results, then section \ref{sec:Adopted training method} goes over our adopted method which appears to provide more stable training with fewer parameters.

%TODO mix of L1 and SSIM: cite https://pdfs.semanticscholar.org/0434/70c64627c074e1a7634a2508ee7e4ec98cd7.pdf
\subsection{Initial training method}\label{sec:Initial training method}
Our initial (c)GAN training method is similar to that of \cite{pix2pix} but with an unequal learning ratio for the discriminator and generator (typically 1:3), because the generator does not learn well when the discriminator is too strong. The method consists of training the discriminator with both a real and a generated minibatch of images, then training the generator using a loss function made of the updated discriminator for high-frequencies and the $\ell 1$ loss for smooth textures. We enhanced the network further by adding the \ac{SSIM} loss.

We found that a generative network trained with the discriminator from the start would never learn to perform well, but a pre-trained generative network could often perform better over time (although a balance must be reached because the discriminator cannot catch up to a too well-trained generator). We added a minimum SSIM score over a specified number of consecutive iterations before adding the discriminator as part of the generator's loss. Although the discriminator is being trained all along, the generator does not receive its feedback until the set threshold is met. From this point the loss function is a weighted combination of the discriminator's \ac{MSE} loss (typically 0.75), the \ac{SSIM} index (0.20) which ensures stability and image quality, and the $\ell 1$ loss (0.05) which provides some smoothness to prevent excessive high-frequency details caused by the discriminator. 

Balanced initialization is crucial as experimental work has shown that using the discriminator too soon results in a generator whose only focus is to trick the discriminator and the image quality suffers to the point where the generator loses and its gradient vanishes. Starting off with a well-trained generator on the other hand gives no chance to the discriminator which remains forever indecisive.

The network is still highly susceptible to failure after initialization. Common issues are overconfidence (with eventual mode collapse where the network outputs the same result), vanishing gradients, and indecision, therefore a good balance must be maintained all along the training process. We provide the discriminator's \ac{MSE} loss with noisy labels as recommended by Salimans et al. \cite{gantechniques}\cite{gantutorial} (minus 0 to 0.05 probabilities on real images) to prevent overconfidence. There is typically a 0.33 to 0.5 training ratio between the discriminator and the generator, the imbalance ensures that the two networks are not constantly trying to overcome each other's latest update. This ratio is lowered to 0.1 when the discriminator gets too accurate (95\%), and it is increased to 0.9 when the discriminator has approximately 50\% or below accuracy. (50\% is the ideal target but it often indicates an indecisive discriminator.)

\subsection{Adopted (c)GAN training method}\label{sec:Adopted training method}

We needed a more robust method which can handle varying strength between the discriminator and the generator, that is, the generator must not always learn when the discriminator has to catch up, a constant ratio may end up promoting imbalance, and it may be beneficial for the two networks to learn on different batches of data rather than immediately adjusting for the other's network last changes.

Our current method uses the discriminator's normalized loss to determine whether the discriminator and the generator get to learn. A denoised batch is generated, then the discriminator learns if its previous normalized loss is smaller than a uniformly distributed random number between 0 and 1. The generator then learns if the discriminator did not learn or if the discriminator's previous performance is greater than another uniformly distributed random number.

The discriminator's normalized loss is between 0 and 1 where 0.5 represents indecision or being right half of the time. For this we simply invert the \ac{MSE} by taking its square root for each set of labels, and we take the average of the two. The generator learns from the discriminator's current (updated) state rather than its previous state as in the previous method, because this saves significant memory and complexity. All thresholding parameters are removed, but we introduced a variable which can be used to give the discriminator an (dis)advantage; that is, whether a network learns is determined by the discriminator's previous loss plus that parameter. For example the intended use of the discriminator advantage variable would be that if it is set to 0.1 and the discriminator has a loss of 0.5, then the discriminator will have a $0.5+0.1=0.6$ probability of learning instead of 0.5 and the generator will learn with a probability of $0.5-0.1=0.4$.)


% should investigate: https://arxiv.org/abs/1803.07422 (Patch-Based Image Inpainting with Generative Adversarial Networks)
The (c)GAN training procedure is summarized as algorithm \ref{alg:gantrain}. The variables (losses and predictions) are tensors which may contain any number of scalars as well as the whole computation graph (history) and gradients needed to perform the backpropagation.


\begin{algorithm}
\caption{(c)GAN training procedure}\label{alg:gantrain}
\begin{algorithmic}[1]
\FORALL{clean\_batch, noisy\_batch $\in$ Dataset}
\STATE generated\_batch $\leftarrow$ generator(noisy\_batch) \COMMENT{Denoised}
\STATE \COMMENT{Train the discriminator}
\IF{discriminator learns}
\STATE \COMMENT{discriminator learns = discriminator's previous normalized loss > random[0,1]}
\STATE ADAM\_optimizer\_D.clear\_gradient()
\IF{discriminator.is\_conditional}
\STATE fake\_minibatch $\leftarrow$ concatenate(
\STATE \quad remove\_borders(noisy\_batch),
\STATE \quad remove\_borders(generated\_batch))
\STATE real\_minibatch $\leftarrow$ concatenate(
\STATE \quad remove\_borders(noisy\_batch),
\STATE \quad remove\_borders(clean\_batch))
\ELSE
\STATE fake\_minibatch $\leftarrow$ remove\_borders(generated\_batch)
\STATE real\_minibatch $\leftarrow$ remove\_borders(clean\_batch)
\ENDIF
\STATE predictions\_on\_real\_data $\leftarrow$ discriminator(real\_minibatch)
\STATE loss\_real\_D $\leftarrow$ \ac{MSE}(
\STATE \quad predictions\_on\_real\_data,
\STATE \quad generate\_noisy\_probabilities(\TRUE))
\STATE loss\_real\_D.backpropagate()
\STATE predictions\_on\_fake\_data $\leftarrow$
\STATE \quad discriminator(fake\_minibatch.detach\_from\_graph())
\STATE loss\_fake\_D $\leftarrow$ \ac{MSE}(predictions\_on\_fake\_data, \FALSE)
\STATE loss\_fake\_D.backpropagate()
\STATE ADAM\_optimizer\_D.update\_weights()
\ENDIF
\STATE \COMMENT{Train the generator}
\IF{generator learns}
\STATE \COMMENT{generator learns = discriminator didn't learn or discriminator's last normalized loss < random[0,1]}
\STATE predictions\_on\_fake\_data $\leftarrow$ discriminator(fake\_minibatch)
\STATE loss\_G\_GAN $\leftarrow$ \ac{MSE}(predictions\_on\_fake\_data, \TRUE)
\STATE loss\_G\_SSIM $\leftarrow$ \ac{SSIM}(
\STATE \quad remove\_borders(generated\_batch),
\STATE \quad remove\_borders(clean\_batch))
\STATE loss\_G\_$\ell 1\leftarrow \ell 1$(
\STATE \quad remove\_borders(generated\_batch),
\STATE \quad remove\_borders(clean\_batch))
\STATE loss\_G\_weighted $\leftarrow$ 
\STATE \quad loss\_G\_GAN $\times (1- $ weight\_loss\_SSIM $-$ weight\_loss\_$\ell 1)$
\STATE \quad $+$ loss\_G\_SSIM $\times$ weight\_loss\_SSIM
\STATE \quad $+$ loss\_G\_$\ell 1 \times$ weight\_loss\_$\ell 1$
\STATE loss\_G\_weighted.backpropagate()
\STATE ADAM\_optimizer\_G.update\_weights()
\STATE ADAM\_optimizer\_G.clear\_gradient()
\ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}
