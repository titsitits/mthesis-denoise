\chapter{Conclusion}
%- Discriminator loss
%needs to be much better
%- multi-scale (pix2pixHD)

We investigated the use of deep learning to solve the denoising problems on photographic images and found that convolutional neural networks outperform conventional denoising methods; state-of-the-art denoising performance is achieved with the use of quality training data. Most research to date has involved training and testing models by adding artificial noise to ground-truth data and this method results in poor performance, as Pl√∂tz and Roth \cite{darmstadt} and our own experiment \ref{exp:nindart} have shown. No such complete dataset was available prior to our research; therefore, we created and released the \acf{NIND}, a dataset of photographic ISO noise with scenes captured using multiple ISO values (and matching settings) which can be used to train a blind denoising model. We found the performance obtained with a single \acl{CNN} trained on the \ac{NIND} to be excellent on a wide variety of scenes, even dynamic ones which could not be captured in the dataset.

A few images remained somewhat unsatisfactory after denoising with a single U-Net model trained on the \ac{NIND}, primarily those of human faces which could look unnaturally smooth in the absence of noise. The excessive smoothing is normally caused by the conventional loss function which favors a blurry result because there is a one-to-many mapping between a noisy image and its possible denoised representations. We developed a framework to train conditional generative adversarial networks for denoising as a way to alleviate this excessive smoothing. \ac{cGAN} are expected to produce more realistic results and generate high-frequencies because the discriminator (which is used as a loss function) is trained to recognize generated images, rather than an exact match with the ground-truth. We found that the resulting denoised images would sometimes provide more natural looking features on human subjects, but that was not always the case. Further work showed that using a combination of multiple different discriminative networks results in a generator that creates believable skin textures even without domain-specific training. The (c)\ac{GAN} training process is much more finicky than that of a conventional convolutional neural network and the results are very similar in most cases. As such, we do not consider \acp{cGAN} to be a necessary update over conventional \acp{CNN} for general image denoising, though they do provide an appreciable improvement in some edge cases. A great benefit of \acp{cGAN} is that they can be used to train the generator without paired data (given a trained discriminator). In some cases the discriminator can be trained without paired data as well, as is the case of unconditional \acp{GAN} and possibly specially designed \acp{cGAN}. One such design could be to feed the discriminator with a variable-noise blurred version of the image as its noisy observation. This process could be used to better handle faces or any other problematic type of images that cannot be included in a paired dataset.

Additional research following from our results includes finding and working with a images that are not well handled by the paired dataset, taking advantage of the fact that \acp{GAN} can work with unpaired data. Different types of \ac{GAN} loss functions can also be investigated. We have investigated the use of \acp{LSGAN} (\ac{MSE}) and \acp{DCGAN} (\ac{BCE}) in our work, but other types such as the \ac{WGAN} may provide greater performance and stability. The ``Hul'' generative and discriminative architecture we introduce perform well but inference remains more computationally intensive than with the U-Net architecture; more assessments should be performed to determine which building blocks can be trimmed without negatively affecting performance. Likewise, more tests should be performed to determine the ideal weights for each loss function in a \ac{GAN} system, and it may be worth training a \ac{cGAN} model until convergence and examining the result. Finally, we intend to implement a light \ac{CNN} denoising model such as U-Net within an open-source photography development software in order to transition deep learning denoising from a purely scientific research field to widespread application.

In sum, the work we present here has shown that convolutional neural networks provide state-of-the-art performance in denoising applications when given appropriate data; the network architecture being secondary as most networks we experimented with learned to denoise effectively (albeit some more slowly). We also developed a working framework to train conditional generative adversarial networks for image denoising; these networks can potentially obtain greater performance with more difficult subjects. We believe this information, along with the \acl{NIND} we present here, will substantially improve the field of image denoising and lead to the development of more efficient techniques that can be used in digital image processing applications.

%- train a general network with specialized dataset

%- WGAN

%- batch same noise samples or samples from one image/noise at a time to take advantage of BN

%further fine-tuning of the discriminator: eg BN before/after, lighter generator

%PatchGAN needs carefully balanced loss because high frequencies
