Namespace(batch_size=18, beta1=0.5, compute_SSIM_anyway=False, cuda_device=2, d_activation='PReLU', d_funit=30, d_loss_function='MSE', d_lr=0.0003, d_model_path=None, d_network='Hulf112Disc', d_weights_dict_path=None, debug_options=None, discriminator_advantage=0.1, epochs=9001, freeze_generator=False, g_activation='PReLU', g_funit=32, g_lr=0.0003, g_model_path=None, g_network='Hulb128Net', g_weights_dict_path=None, min_lr=5e-08, not_conditional=False, patience=3, start_epoch=1, test_reserve=None, threads=6, time_limit=172800, train_data=None, weight_L1=0.05, weight_SSIM=0.2)
cmd: python3 gan_train.py --batch_size 18 --cuda_device 2 --weight_SSIM 0.2 --weight_L1 0.05 --d_funit 30 --discriminator_advantage 0.1 --d_network Hulf112Disc
Epoch 1 batch 1/4890: loss D: 0.489407 (range (r-r+f-f+): -0.0018, -2.5e-05, -0.0019, 0.014)
Epoch 1 batch 2/4890: loss D: 0.515869 (range (r-r+f-f+): 0.21, 0.56, 0.23, 0.7)
Epoch 1 batch 3/4890: loss D: 0.480843 (range (r-r+f-f+): 0.38, 0.74, 0.42, 0.76)
Epoch 1 batch 4/4890:                                                                               loss G: weighted: 0.378, SSIM: 0.843, D: 0.505, L1: 0.364
Epoch 1 batch 5/4890: loss D: 0.507954 (range (r-r+f-f+): 0.34, 0.86, 0.34, 1.0)
Epoch 1 batch 6/4890:                                                                               loss G: weighted: 0.458, SSIM: 0.656, D: 0.648, L1: 0.249
Epoch 1 batch 7/4890: loss D: 0.520472 (range (r-r+f-f+): -0.0011, 0.65, -0.00052, 0.68)
Epoch 1 batch 8/4890:                                                                               loss G: weighted: 0.434, SSIM: 0.724, D: 0.605, L1: 0.303
Epoch 1 batch 9/4890:                                                                               loss G: weighted: 0.430, SSIM: 0.706, D: 0.604, L1: 0.312
Epoch 1 batch 10/4890:                                                                              loss G: weighted: 0.439, SSIM: 0.769, D: 0.599, L1: 0.315
Epoch 1 batch 11/4890:                                                                              loss G: weighted: 0.388, SSIM: 0.609, D: 0.581, L1: 0.272
Epoch 1 batch 12/4890:                                                                              loss G: weighted: 0.379, SSIM: 0.613, D: 0.572, L1: 0.234
Epoch 1 batch 13/4890:                                                                              loss G: weighted: 0.381, SSIM: 0.629, D: 0.569, L1: 0.241
Epoch 1 batch 14/4890:                                                                              loss G: weighted: 0.374, SSIM: 0.594, D: 0.571, L1: 0.226
Epoch 1 batch 15/4890: loss D: 0.537741 (range (r-r+f-f+): 0.14, 0.93, 0.11, 0.97),                 loss G: weighted: 0.440, SSIM: 0.604, D: 0.637, L1: 0.294
Epoch 1 batch 16/4890: loss D: 0.546838 (range (r-r+f-f+): 0.07, 0.92, 0.052, 1.0)
Epoch 1 batch 17/4890: loss D: 0.518222 (range (r-r+f-f+): 0.15, 0.68, 0.23, 0.88)
Epoch 1 batch 18/4890: loss D: 0.503280 (range (r-r+f-f+): 0.23, 1.0, 0.26, 0.91),                  loss G: weighted: 0.476, SSIM: 0.631, D: 0.668, L1: 0.287
Epoch 1 batch 19/4890:                                                                              loss G: weighted: 0.407, SSIM: 0.527, D: 0.620, L1: 0.267
Epoch 1 batch 20/4890: loss D: 0.508218 (range (r-r+f-f+): 0.28, 0.85, 0.15, 0.85),                 loss G: weighted: 0.369, SSIM: 0.551, D: 0.576, L1: 0.202
Epoch 1 batch 21/4890:                                                                              loss G: weighted: 0.403, SSIM: 0.563, D: 0.611, L1: 0.208
Epoch 1 batch 22/4890:                                                                              loss G: weighted: 0.368, SSIM: 0.534, D: 0.578, L1: 0.212
Epoch 1 batch 23/4890: loss D: 0.555795 (range (r-r+f-f+): 0.11, 0.82, 0.11, 0.94)
Epoch 1 batch 24/4890: loss D: 0.545946 (range (r-r+f-f+): 0.044, 1.1, 0.13, 1.1)
Epoch 1 batch 25/4890: loss D: 0.524478 (range (r-r+f-f+): 0.2, 1.0, 0.19, 1.0)
