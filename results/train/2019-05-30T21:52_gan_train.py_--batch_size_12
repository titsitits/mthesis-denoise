Namespace(batch_size=12, beta1=0.5, cuda_device=0, d_activation='PReLU', d_funit=24, d_loss_function='MSE', d_lr=0.0003, d_model_path=None, d_network='Hul112Disc', d_weights_dict_path=None, epochs=9001, g_activation='PReLU', g_funit=32, g_lr=0.0003, g_model_path=None, g_network='Hulb128Net', g_weights_dict_path=None, min_lr=5e-08, not_conditional=False, test_reserve=None, threads=8, time_limit=172800, train_data=None, weight_L1=0.05, weight_SSIM=0.2)
cmd: python3 gan_train.py --batch_size 12
Epoch 1 batch 1/7335: loss D: 0.980757 (range (r-r+f-f+): -0.0021, -0.0013, -0.0022, -0.0015)
Epoch 1 batch 2/7335: loss D: 0.980047 (range (r-r+f-f+): -0.0023, -0.0011, -0.0023, -0.00032)
Epoch 1 batch 3/7335: loss D: 0.974964 (range (r-r+f-f+): -0.0021, -0.0011, -0.0017, -0.00063)
Epoch 1 batch 4/7335: loss D: 0.976819 (range (r-r+f-f+): -0.0015, -4.9e-05, -0.0017, -6.9e-05)
Epoch 1 batch 5/7335: loss D: 0.971929 (range (r-r+f-f+): -0.0013, 0.098, -0.0012, -0.00044)
Epoch 1 batch 6/7335: loss D: 0.968638 (range (r-r+f-f+): -0.0011, 0.055, -0.0013, -3.9e-05)
Epoch 1 batch 7/7335: loss D: 1.015705 (range (r-r+f-f+): -0.0011, 0.35, -0.001, 0.23)
Epoch 1 batch 8/7335: loss D: 1.099884 (range (r-r+f-f+): -0.00089, 0.46, -0.0011, 0.58)
Epoch 1 batch 9/7335: loss D: 1.159329 (range (r-r+f-f+): -0.0011, 0.95, -0.0011, 0.67)
Epoch 1 batch 10/7335: loss D: 1.084178 (range (r-r+f-f+): -0.00098, 0.76, -0.00099, 0.55)
Epoch 1 batch 11/7335: loss D: 1.144347 (range (r-r+f-f+): -0.00095, 0.98, -0.0011, 0.57)
Epoch 1 batch 12/7335: loss D: 1.110023 (range (r-r+f-f+): -0.0013, 0.64, -0.0009, 0.64)
Epoch 1 batch 13/7335: loss D: 1.054594 (range (r-r+f-f+): -0.00098, 0.57, -0.001, 0.4)
Epoch 1 batch 14/7335: loss D: 1.068098 (range (r-r+f-f+): -0.0011, 0.63, -0.0011, 0.52)
Epoch 1 batch 15/7335: loss D: 1.108598 (range (r-r+f-f+): -0.0011, 0.73, -0.0011, 0.7)
Epoch 1 batch 16/7335: loss D: 1.022274 (range (r-r+f-f+): -0.00094, 0.64, -0.00081, 0.6)
Epoch 1 batch 17/7335: loss D: 1.015420 (range (r-r+f-f+): -0.0011, 0.71, -0.00093, 0.57)
Epoch 1 batch 18/7335: loss D: 1.069462 (range (r-r+f-f+): 0.059, 0.66, 0.07, 0.71)
Epoch 1 batch 19/7335: loss D: 0.989672 (range (r-r+f-f+): 0.33, 0.77, 0.2, 0.79)
Epoch 1 batch 20/7335: loss D: 0.952053 (range (r-r+f-f+): 0.36, 0.68, 0.22, 0.69)
Epoch 1 batch 21/7335: loss D: 0.957982 (range (r-r+f-f+): 0.25, 1.1, 0.23, 0.75)
Epoch 1 batch 22/7335: loss D: 0.959915 (range (r-r+f-f+): 0.44, 0.72, 0.42, 0.81)
Epoch 1 batch 23/7335: loss D: 0.899735 (range (r-r+f-f+): 0.16, 0.7, 0.13, 0.56)
Epoch 1 batch 24/7335: loss D: 0.893288 (range (r-r+f-f+): 0.29, 0.61, 0.17, 0.53)
Epoch 1 batch 25/7335: loss D: 0.895043 (range (r-r+f-f+): 0.33, 1.1, 0.21, 0.61)
Epoch 1 batch 26/7335: loss D: 0.858426 (range (r-r+f-f+): 0.38, 0.95, 0.21, 0.8)
Epoch 1 batch 27/7335: loss D: 0.905816 (range (r-r+f-f+): 0.22, 0.86, 0.019, 0.78)
Epoch 1 batch 28/7335: loss D: 0.878583 (range (r-r+f-f+): 0.17, 0.83, 0.12, 0.65)
Epoch 1 batch 29/7335: loss D: 0.769788 (range (r-r+f-f+): 0.31, 0.79, -5.3e-05, 0.46),	 loss G: SSIM: 0.777, L1: 0.277, D: 0.506, weighted: 0.195
Epoch 1 batch 30/7335: loss D: 0.892259 (range (r-r+f-f+): 0.35, 1.0, 0.22, 0.62)
Epoch 1 batch 31/7335: loss D: 0.838091 (range (r-r+f-f+): 0.41, 0.85, 0.15, 0.63)
Epoch 1 batch 32/7335: loss D: 0.858421 (range (r-r+f-f+): 0.35, 0.96, 0.2, 0.89),	 loss G: SSIM: 0.635, L1: 0.221, D: 0.496, weighted: 0.163
Epoch 1 batch 33/7335: loss D: 0.868310 (range (r-r+f-f+): 0.23, 0.72, 0.032, 0.73)
Epoch 1 batch 34/7335: loss D: 0.956105 (range (r-r+f-f+): 0.35, 1.1, 0.25, 0.87)
Epoch 1 batch 35/7335: loss D: 0.754884 (range (r-r+f-f+): 0.25, 0.96, -0.00022, 0.41)
